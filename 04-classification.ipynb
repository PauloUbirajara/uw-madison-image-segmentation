{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Separar/validar dados\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Redução de dimensionalidade\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Representação vetorial para imagem\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.efficientnet import (\n",
    "\tEfficientNetB0, EfficientNetB1,\n",
    "\tEfficientNetB2, EfficientNetB3,\n",
    "\tEfficientNetB4, EfficientNetB5,\n",
    "\tEfficientNetB6, EfficientNetB7\n",
    ")\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Carregar imagens de clusters em pastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_test_size = 0.2\n",
    "undersampling_size = 1300 # -1 para não fazer undersampling\n",
    "\n",
    "diretorio = './clusters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = next(os.walk(diretorio))[1]\n",
    "\n",
    "targets = targets[1:len(targets)]\n",
    "\n",
    "dados = []\n",
    "\n",
    "for classe in targets:\n",
    "    imagens = os.listdir(os.join([diretorio,classe]))\n",
    "    i = 0\n",
    "    for img in imagens:\n",
    "        i+=1\n",
    "        \n",
    "        if img.endswith('.jpg'):\n",
    "            caminho_imagem = os.join([diretorio, classe, '/', img])\n",
    "            dados.append([caminho_imagem, classe])\n",
    "        \n",
    "        if(i == undersampling_size and undersampling_size != -1):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Separar features e targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = np.array(dados)\n",
    "\n",
    "np.random.shuffle(dados)\n",
    "            \n",
    "df_dados = pd.DataFrame(dados, columns=['image','target'])\n",
    "\n",
    "df_dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbedder():\n",
    "    # return EfficientNetB0(weights='imagenet', include_top=False)\n",
    "    # return EfficientNetB2(weights='imagenet', include_top=False)\n",
    "    return EfficientNetB3(weights='imagenet', include_top=False)\n",
    "    # return EfficientNetB4(weights='imagenet', include_top=False)\n",
    "    # return EfficientNetB7(weights='imagenet', include_top=False)\n",
    "    # return InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largura, altura = 150, 150\n",
    "\n",
    "def embedding(embedder,img_path):\n",
    "    img = image.load_img(img_path, target_size=(altura, largura))\n",
    "    embed = image.img_to_array(img)\n",
    "    embed = np.expand_dims(embed, axis=0)\n",
    "    # embed = preprocess_input(embed)\n",
    "\n",
    "    features = embedder.predict(embed)\n",
    "\n",
    "    return features[0][0][0]\n",
    "\n",
    "embedder = getEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_dados['target'].array\n",
    "\n",
    "# array_features = []\n",
    "# for x in dados:\n",
    "#     array_features.append(embedding(embedder,x[0]))\n",
    "array_features = pd.DataFrame(dados).apply(lambda x: embedding(embedder,x['image']), axis=1)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "array_features = scaler.fit_transform(array_features)\n",
    "\n",
    "df_features = pd.DataFrame(array_features)\n",
    "\n",
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Reduzir dimensionalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=15)\n",
    "\n",
    "array_red = model.fit_transform(df_features) \n",
    "\n",
    "df_tsne = pd.DataFrame(array_red)\n",
    "\n",
    "df_tsne['target'] = target\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "sns.scatterplot(data=df_tsne, x=df_tsne[0], y=df_tsne[1], hue=df_tsne['target'], palette=\"colorblind\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Treinamento de modelo/rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    return RandomForestClassifier(n_jobs=20)\n",
    "    # return LogisticRegression()#n_jobs=20, solver='sag', multi_class='ovr')\n",
    "    # return KNeighborsClassifier(n_neighbors=3,n_jobs=20)\n",
    "    # return XGBClassifier()\n",
    "    # return SGDClassifier(n_jobs=20,early_stopping=True,validation_fraction=0.05)\n",
    "\t\t\n",
    "\t\t# TODO Rede aqui ao invés de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificação de score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(getModel(), df_features.values, target, cv=10)\n",
    "\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicoes = cross_val_predict(getModel(),df_features.values,target,cv=10)\n",
    "\n",
    "cm = confusion_matrix(target, predicoes)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=model.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f49206fcf84a9145e7e21228cbafa911d1ac18292303b01e865d8267a9c448f7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
